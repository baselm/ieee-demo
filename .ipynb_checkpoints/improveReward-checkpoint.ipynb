{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Agent Defiend"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from subprocess import Popen, PIPE\n",
    "import os\n",
    "from tempfile import mkdtemp\n",
    "from werkzeug import secure_filename\n",
    "import requests\n",
    "import gym\n",
    "from gym import error, spaces, utils\n",
    "from gym.utils import seeding\n",
    "from gym import spaces, logger\n",
    "import subprocess\n",
    "from subprocess import Popen, PIPE\n",
    "import numpy as np \n",
    "import time \n",
    "import pandas as pd \n",
    "class FooEnv(gym.Env):\n",
    "    metadata = {'render.modes': ['human']}\n",
    "    def __init__(self):\n",
    "        print('__init__')\n",
    "        self.maxNode = 5 \n",
    "        self.minNode =1 \n",
    "        self.node = 1\n",
    "        self.cpu_axis  = self.get_cpu_observation()\n",
    "        self.mem_axis = self.get_mem_observation()\n",
    "        self.disk_axis = self.get_disk_observation()\n",
    "        self.net_axis  = self.get_net_observation()\n",
    "        self.action_space = spaces.Discrete(9)\n",
    "        high = np.array([\n",
    "            self.get_cpu_observation(),\n",
    "            self.get_mem_observation(),\n",
    "            self.get_disk_observation(),\n",
    "            self.get_net_observation()])\n",
    "        low = np.array([\n",
    "            np.zeros(5),\n",
    "            np.zeros(5),\n",
    "            np.zeros(5),\n",
    "            np.zeros(5)])\n",
    "        self.observation_space = spaces.Box(low, high, dtype=np.float32)\n",
    "        self.seed()\n",
    "        self.obs= 0\n",
    "        self.obs = self.get_observation()\n",
    "        self.viewer = None\n",
    "        self.state = self.get_observation()\n",
    "        self.attempt = 0 \n",
    "        self.steps_beyond_done = None\n",
    "        self.done = False\n",
    "        self.adapte_cpu= False  \n",
    "        self.adapte_mem= False \n",
    "        self.adapte_disk= False \n",
    "        self.adapte_net= False \n",
    "        \n",
    "    def seed(self, seed=None):\n",
    "        self.np_random, seed = seeding.np_random(seed)\n",
    "        return [seed]\n",
    "    \n",
    "    def step(self, action):\n",
    "        assert self.action_space.contains(action), \"%r (%s) invalid\"%(action, type(action))\n",
    "        state = self.get_observation()\n",
    "        #past_stat = self.state\n",
    "        #print(state)\n",
    "        #Find the Utility Prefernces \n",
    "        # Select action \n",
    "        # get the reward value\n",
    "       \n",
    "        maxUtility = np.amax(self.obs[:,4])\n",
    "        utilityType = np.argmax(self.obs[:,4])\n",
    "        if utilityType== 0:\n",
    "            self.adapte_cpu=True \n",
    "        elif utilityType== 1:\n",
    "            self.adapte_mem = True\n",
    "        elif utilityType== 2:\n",
    "            self.adapte_disk = True\n",
    "        elif utilityType== 3:\n",
    "            self.adapte_net = True\n",
    "        self.attempt += 1\n",
    "        print('self.adapte_cpu: ', self.adapte_cpu, 'self.adapte_mem:', self.adapte_mem, 'self.adapte_disk:',self.adapte_disk,'self.adapte_net:', self.adapte_net )\n",
    "        done=False\n",
    "        reward=0\n",
    "        #Here \n",
    "     \n",
    "        if action == 0:\n",
    "            print(\"Stay in State S0\")\n",
    "            self.obs = self.get_observation()\n",
    "            reward= 1 - np.amax(self.obs[:,3]) \n",
    "        elif action == 1:\n",
    "            print(\"Stay in State S0\")\n",
    "            self.obs = self.get_observation()\n",
    "            reward= 1 - np.amax(self.obs[:,3])  \n",
    "            if (self.attempt>300):\n",
    "                done = True\n",
    "                reward= 1\n",
    "            else:\n",
    "                done= False \n",
    "            info = \"Stay in State S0\"\n",
    "            print(\"reward: \",reward, np.amax(self.obs[:,4]))\n",
    "        elif action == 2: \n",
    "            print(\"Scale Service UP S2\")\n",
    "            try:\n",
    "                response = requests.get(' http://192.168.99.100:5000/services/vscale/web/'+ str(self.attempt) + '/' + str(self.cpu_axis[0])+'/'+str(self.cpu_axis[3]))\n",
    "                results = response.json()\n",
    "                if results['result']=='Service converged':\n",
    "                    done=True \n",
    "                    self.obs = self.get_observation()\n",
    "                    reward= 1 \n",
    "                else:\n",
    "                    done= False\n",
    "                    print(results)\n",
    "\n",
    "                    self.obs = self.get_observation()\n",
    "                    reward= 1 - np.amax(self.obs[:,3])  \n",
    "                    print(reward)\n",
    "            finally:\n",
    "                info = \"Scale Up Move to State S1\"\n",
    "                print(\"reward: \",reward, np.amax(self.obs[:,4]))\n",
    "                pass\n",
    "\n",
    "        elif action == 3: \n",
    "            print(\"Maintain Cluster State S4 and delete dangling docker containers\")\n",
    "          \n",
    "            self.obs = self.get_observation()\n",
    "            reward= 1 - np.amax(self.obs[:,3])\n",
    "            print(\"reward: \",reward, np.amax(self.obs[:,4]))\n",
    "            done= False\n",
    "            if (self.attempt>300):\n",
    "                done = True\n",
    "                info = \"delete dangling docker containers S4\"\n",
    "                cur_dir = os.getcwd()\n",
    "                filepath = os.path.join(cur_dir, 'cleancontainers.sh')\n",
    "                print (filepath)\n",
    "                res= subprocess.call(filepath, shell=True)\n",
    "                print (res)\n",
    "                reward = 1\n",
    "        elif action == 4: \n",
    "\n",
    "            current_state = self.obs\n",
    "\n",
    "            if (self.node <= self.maxNode and self.node >= self.minNode ):\n",
    "                print(\"Add Node S4\")\n",
    "                cur_dir = os.getcwd()\n",
    "                filepath = os.path.join(cur_dir, 'addNode.sh')\n",
    "                print (filepath)\n",
    "                res= subprocess.call(filepath, shell=True)\n",
    "                print (res)\n",
    "                info = \"Add Node S4\"\n",
    "                self.obs = self.get_observation()\n",
    "                reward= 1  \n",
    "                print(\"reward: \",reward, np.amax(self.obs[:,4]))\n",
    "                done= True\n",
    "                self.node +=1\n",
    "                 \n",
    "            elif self.node==5:\n",
    "                    done=True \n",
    "                    reward=1\n",
    "            else:\n",
    "                print(\"Add Node to Cluster State S4: \", self.attempt)\n",
    "                done= False\n",
    "                self.obs = self.get_observation()\n",
    "                reward= 1 - np.amax(self.obs[:,3])\n",
    "                print(\"reward: \",reward, np.amax(self.obs[:,4]))\n",
    "                \n",
    "        elif action == 5: \n",
    "\n",
    "            self.obs = self.get_observation()\n",
    "            if (self.node <= self.maxNode and self.node > self.minNode ):\n",
    "                print(\"Delete Node S5\")\n",
    "                cur_dir = os.getcwd()\n",
    "                filepath = os.path.join(cur_dir, 'deleteNode.sh')\n",
    "                print (filepath)\n",
    "                res= subprocess.call(filepath, shell=True)\n",
    "                print (res)\n",
    "                info = \"Delete Node S5\"\n",
    "                reward= 1  \n",
    "                print(\"reward: \",reward, np.amax(self.obs[:,4]))\n",
    "                done= True\n",
    "                 \n",
    "                self.node -=1\n",
    "               \n",
    "            else:\n",
    "                print(\"Maintain Cluster State S5: \", self.attempt, self.node, self.minNode, self.maxNode)\n",
    "                done= False\n",
    "                reward= 1 - np.amax(self.obs[:,3])\n",
    "                print(\"reward: \",reward)\n",
    "                if self.node==1:\n",
    "                    done=True \n",
    "                    reward=1\n",
    "\n",
    "        elif action==6:\n",
    "            print(\"freedisk Space S6\")\n",
    "            cur_dir = os.getcwd()\n",
    "            filepath = os.path.join(cur_dir, 'freedisk.sh')\n",
    "            print (filepath)\n",
    "            res= subprocess.call(filepath, shell=True)\n",
    "            print (res)\n",
    "            info = \"freedisk Node S6\"\n",
    "            reward= 1  \n",
    "            print(\"reward: \",reward, np.amax(self.obs[:,4]))\n",
    "            done= True\n",
    "             \n",
    "\n",
    "        elif action == 7:\n",
    "            print(\"rollback and enforce new cluster\")\n",
    "            #Reward = max of utility fitness\n",
    "            try:\n",
    "                cur_dir = os.getcwd()\n",
    "                #filepath = os.path.join(cur_dir, 'newcluster.sh')\n",
    "                #print (filepath)\n",
    "                #res= subprocess.call(filepath, shell=True)\n",
    "                #print (res)\n",
    "                info = \"rollback and enforce new  cluster S7\"\n",
    "                time.sleep(300)\n",
    "                reward= 1 \n",
    "                print(\"reward: \",reward, np.amax(self.obs[:,4]))\n",
    "                done= True\n",
    "                 \n",
    "                self.obs = self.get_observation()\n",
    "                reward= 1  \n",
    "                print(reward)\n",
    "                info = \"rollback and enforce new cluster\"\n",
    "            finally:\n",
    "                pass\n",
    "              \n",
    "\n",
    "        elif action==8:\n",
    "            if (self.attempt>10 and self.attempt <13 and self.node < self.maxNode and self.node >= self.minNode ):\n",
    "                \n",
    "                cur_dir = os.getcwd()\n",
    "                filepath = os.path.join(cur_dir, 'manager.sh')\n",
    "                print (filepath)\n",
    "                res= subprocess.call(filepath, shell=True)\n",
    "                print (res)\n",
    "                info = \"Add Manager node S8\"\n",
    "                self.node += 1\n",
    "                reward= 1 \n",
    "                print(\"reward: \",reward, np.amax(self.obs[:,4]), \"Node: \", self.node)\n",
    "                done= True\n",
    "                 \n",
    "            else:\n",
    "                print(\"Maintain Cluster State S8\", self.attempt)\n",
    "                reward= 1 - np.amax(self.obs[:,3])\n",
    "                done= False\n",
    "                print(\"reward: \",reward, np.amax(self.obs[:,4]))\n",
    "        else: \n",
    "            print (\"action not defined\")\n",
    "            self.obs = self.get_observation()\n",
    "            done= False\n",
    "            reward= -1\n",
    "            info = \"action not defined\"\n",
    "        \n",
    "        if done: \n",
    "            reward = 1.0\n",
    "        elif self.steps_beyond_done is None:\n",
    "            #Adaptation Failed \n",
    "            reward = 0.0 \n",
    "            self.steps_beyond_done = 0\n",
    "        else: \n",
    "            if self.steps_beyond_done == 1:\n",
    "                logger.warn(\"You are calling 'step()' even though this environment has already returned done = True. You should always call 'reset()' once you receive 'done = True' -- any further steps are undefined behavior.\")\n",
    "                self.steps_beyond_done += 1\n",
    "                reward = 0.0\n",
    "         \n",
    "        return self.obs, reward, done, {}\n",
    "    def reset(self):\n",
    "        self.state = self.get_observation()\n",
    "        self.steps_beyond_done = None\n",
    "        self.adapte_cpu= False  \n",
    "        self.adapte_mem= False \n",
    "        self.adapte_disk= False \n",
    "        self.adapte_net= False \n",
    "        self.maxNode = 5 \n",
    "        self.minNode =1 \n",
    "        return np.array(self.state)\n",
    "    def render(self, mode='human', close=False):\n",
    "        logger.warn(\"View is not allowed in this environment\")\n",
    "        return 0 \n",
    "    def close(self):\n",
    "        if self.viewer:\n",
    "            self.viewer.close()\n",
    "            self.viewer = None\n",
    "    def get_observation(self):\n",
    "        try:\n",
    "            self.disk_axis = self.get_disk_observation() \n",
    "            self.mem_axis = self.get_mem_observation()\n",
    "            self.cpu_axis = self.get_cpu_observation()\n",
    "            self.net_axis = self.get_net_observation()\n",
    "            obs =np.vstack((self.cpu_axis,self.mem_axis, self.disk_axis, self.net_axis) )\n",
    "            return obs \n",
    "        finally: \n",
    "            pass \n",
    "        \n",
    "    def get_cpu_observation(self):\n",
    "        try: \n",
    "            response = requests.get('http://192.168.99.100:8888/cpu', timeout=5)\n",
    "            results = response.json()\n",
    "            if len(results) > 0:\n",
    "                    cpu = results['cpu']\n",
    "                    prediction = results['prediction']\n",
    "                    anomalyScore = results['anomalyScore']\n",
    "                    anomalyLikelihood = results['anomalyLikelihood']\n",
    "                    utility_cpu = results['utility_cpu']\n",
    "                    cpu_axis=[cpu, prediction, anomalyScore, anomalyLikelihood, utility_cpu]\n",
    "            return np.array(cpu_axis)\n",
    "        finally: \n",
    "            pass\n",
    "    def get_mem_observation(self):\n",
    "        try:\n",
    "            response = requests.get('http://192.168.99.100:8888/mem', timeout=5)\n",
    "            results = response.json()\n",
    "            if len(results) > 0:\n",
    "                mem = results['mem']\n",
    "                prediction = results['prediction']\n",
    "                anomalyScore = results['anomalyScore']\n",
    "                anomalyLikelihood = results['anomalyLikelihood']\n",
    "                utility_mem = results['utility_mem']\n",
    "                mem_axis=[mem, prediction, anomalyScore, anomalyLikelihood, utility_mem]\n",
    "                return np.array(mem_axis)\n",
    "        finally: \n",
    "            pass\n",
    "    def get_net_observation(self):\n",
    "        try:\n",
    "            response = requests.get('http://192.168.99.100:8888/net', timeout=5)\n",
    "            results = response.json()\n",
    "            if len(results) > 0:\n",
    "                net = results['net']\n",
    "                prediction = results['prediction']\n",
    "                anomalyScore = results['anomalyScore']\n",
    "                anomalyLikelihood = results['anomalyLikelihood']\n",
    "                utility_net = results['utility_net']\n",
    "                net_axis=[net, prediction, anomalyScore, anomalyLikelihood, utility_net]\n",
    "            return np.array(net_axis)\n",
    "        finally:\n",
    "            pass \n",
    "    def get_disk_observation(self):\n",
    "        try:\n",
    "            response = requests.get('http://192.168.99.100:8888/disk', timeout=5)\n",
    "            if response is not None:\n",
    "                results = response.json()\n",
    "                if len(results) > 0:\n",
    "                    disk = results['disk']\n",
    "                    prediction = results['prediction']\n",
    "                    anomalyScore = results['anomalyScore']\n",
    "                    anomalyLikelihood = results['anomalyLikelihood']\n",
    "                    utility_disk = results['utility_disk']\n",
    "            disk_axis=[disk, prediction, anomalyScore, anomalyLikelihood, utility_disk]\n",
    "            return np.array(disk_axis)\n",
    "        finally: \n",
    "            pass\n",
    "\n",
    "    def get_current_state(self):\n",
    "        current_state = self.state\n",
    "         \n",
    "        return current_state"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### call the agent "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import gym\n",
    "import gym_foo\n",
    "\n",
    "env = FooEnv()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "env.reset()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##  call Keras API and Keras rl"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "button": false,
    "new_sheet": false,
    "run_control": {
     "read_only": false
    }
   },
   "outputs": [],
   "source": [
    "from __future__ import division, print_function, unicode_literals\n",
    "import csv\n",
    "import shutil\n",
    "import os\n",
    "import time\n",
    "import requests\n",
    "import subprocess\n",
    "from subprocess import call\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from rl.callbacks import FileLogger, ModelIntervalCheckpoint\n",
    "import pandas as pd \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import gym\n",
    "\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Activation, Flatten\n",
    "from keras.optimizers import Adam\n",
    "\n",
    "from rl.agents.dqn import DQNAgent\n",
    "from rl.policy import BoltzmannQPolicy\n",
    "from rl.memory import SequentialMemory "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "button": false,
    "new_sheet": false,
    "run_control": {
     "read_only": false
    }
   },
   "outputs": [],
   "source": [
    "def reset_graph(seed=42):\n",
    "    tf.reset_default_graph()\n",
    "    tf.set_random_seed(seed)\n",
    "    np.random.seed(seed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "button": false,
    "new_sheet": false,
    "run_control": {
     "read_only": false
    }
   },
   "outputs": [],
   "source": [
    "def save_fig(fig_id, tight_layout=True):\n",
    "    path = os.path.join(PROJECT_ROOT_DIR, \"images\", CHAPTER_ID, fig_id + \".png\")\n",
    "    print(\"Saving figure\", fig_id)\n",
    "    if tight_layout:\n",
    "        plt.tight_layout()\n",
    "    plt.savefig(path, format='png', dpi=300)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# # # MDP \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "button": false,
    "new_sheet": false,
    "run_control": {
     "read_only": false
    }
   },
   "source": [
    "## Deep Q-Learning\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "env.observation_space.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nb_actions= env.action_space.n\n",
    "nb_actions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "env.node"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "button": false,
    "new_sheet": false,
    "run_control": {
     "read_only": false
    }
   },
   "outputs": [],
   "source": [
    "# Next, we build a very simple model.\n",
    "model = Sequential()\n",
    "model.add(Flatten(input_shape=(1,) + env.observation_space.shape))\n",
    "model.add(Dense(16))\n",
    "model.add(Activation('relu'))\n",
    "model.add(Dense(16))\n",
    "model.add(Activation('relu'))\n",
    "model.add(Dense(16))\n",
    "model.add(Activation('relu'))\n",
    "model.add(Dense(nb_actions))\n",
    "model.add(Activation('linear'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "button": false,
    "new_sheet": false,
    "run_control": {
     "read_only": false
    }
   },
   "outputs": [],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "memory = SequentialMemory(limit=5000, window_length=1)\n",
    "policy = BoltzmannQPolicy()\n",
    "dqn = DQNAgent(model=model, nb_actions=nb_actions, memory=memory, nb_steps_warmup=10,\n",
    "               target_model_update=1e-2, policy=policy)\n",
    "dqn.compile(Adam(lr=1e-3), metrics=['mae'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "ENV_NAME=\"improvedRewardv7\"\n",
    "weights_filename = 'mydqn_{}_weights.h5f'.format(ENV_NAME)\n",
    "checkpoint_weights_filename = 'dqn_' + ENV_NAME + '_weights_{step}.h5f'\n",
    "log_filename = 'mydqn_{}_log.json'.format(ENV_NAME)\n",
    "callbacks = [ModelIntervalCheckpoint(checkpoint_weights_filename, interval=5000)]\n",
    "callbacks += [FileLogger(log_filename, interval=5000)]\n",
    "dqn.fit(env, callbacks=callbacks, nb_steps=5000, log_interval=5000,verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dqn.save_weights(weights_filename, overwrite=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dqn.test(env, nb_episodes=10, visualize=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dqn.metrics_names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Finally, evaluate our algorithm for 5 episodes.\n",
    "ENV_NAME=\"micro4\"\n",
    "weights_filename = 'mydqn_{}_weights.h5f'.format(ENV_NAME)\n",
    "checkpoint_weights_filename = 'dqn_' + ENV_NAME + '_weights_{step}.h5f'\n",
    "log_filename = 'mydqn_{}_log.json'.format(ENV_NAME)\n",
    "callbacks = [ModelIntervalCheckpoint(checkpoint_weights_filename, interval=250000)]\n",
    "callbacks += [FileLogger(log_filename, interval=100)]\n",
    "dqn.fit(env, callbacks=callbacks, nb_steps=175, log_interval=10000)\n",
    "\n",
    "#dqn.test(env, nb_episodes=5, visualize=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import argparse\n",
    "import json\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "\n",
    "def visualize_log(filename, figsize=None, output=None):\n",
    "    with open(filename, 'r') as f:\n",
    "        data = json.load(f)\n",
    "    if 'episode' not in data:\n",
    "        raise ValueError('Log file \"{}\" does not contain the \"episode\" key.'.format(filename))\n",
    "    episodes = data['episode']\n",
    "\n",
    "    \n",
    "\n",
    "    # Get value keys. The x axis is shared and is the number of episodes.\n",
    "    keys = sorted(list(set(data.keys()).difference(set(['episode']))))\n",
    "\n",
    "    if figsize is None:\n",
    "        figsize = (35., 15. * len(keys))\n",
    "    f, axarr = plt.subplots(len(keys), sharex=True, figsize=figsize)\n",
    "    for idx, key in enumerate(keys):\n",
    "        axarr[idx].plot(episodes, data[key])\n",
    "        axarr[idx].set_ylabel(key)\n",
    "        \n",
    "    plt.xlabel('episodes')\n",
    "    plt.tight_layout()\n",
    "    if output is None:\n",
    "        plt.show()\n",
    "    else:\n",
    "        plt.savefig(output)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#visualize_log(args.filename, output=args.output, figsize=args.figsize)\n",
    "visualize_log('mydqn_micro_with_swarmed_log.json')\n",
    "#mydqn_micro_with_swarmed_log.json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/anaconda3/lib/python3.6/site-packages/ipykernel_launcher.py:29: UserWarning: matplotlib.pyplot as already been imported, this call will have no effect.\n"
     ]
    }
   ],
   "source": [
    "'''\n",
    "chart_utils.py: Charting utilities for RL experiments.\n",
    "\n",
    "Functions:\n",
    "    load_data: Loads data from csv files into lists.\n",
    "    average_data: Averages data across instances.\n",
    "    compute_conf_intervals: Confidence interval computation.\n",
    "    compute_single_conf_interval: Helper function for above.\n",
    "    _format_title()\n",
    "    plot: Creates (and opens) a single plot using matplotlib.pyplot\n",
    "    make_plots: Puts everything in order to create the plot.\n",
    "    _get_agent_names: Grabs the agent names the experiment parameter file, named @Experiment.EXP_PARAM_FILE_NAME\n",
    "    _get_agent_colors: Determines the relevant colors/markers for the plot.\n",
    "    _is_episodic: Determines if the experiment was episodic from the experiment parameter file, named @Experiment.EXP_PARAM_FILE_NAME\n",
    "    _is_disc_reward()\n",
    "    parse_args: Parse command line arguments.\n",
    "    main: Loads data from a given path and creates plot.\n",
    "\n",
    "Author: David Abel (cs.brown.edu/~dabel)\n",
    "'''\n",
    "\n",
    "# Python imports.\n",
    "from __future__ import print_function\n",
    "import math\n",
    "import decimal\n",
    "import sys\n",
    "import os\n",
    "import matplotlib\n",
    "matplotlib.use('TkAgg')\n",
    "import matplotlib.pyplot as pyplot\n",
    "import numpy as np\n",
    "import subprocess\n",
    "import argparse\n",
    "\n",
    "color_ls = [[118, 167, 125], [102, 120, 173],\\\n",
    "            [198, 113, 113], [94, 94, 94],\\\n",
    "            [169, 193, 213], [230, 169, 132],\\\n",
    "            [192, 197, 182], [210, 180, 226]]\n",
    "\n",
    "# Set font.\n",
    "font = {'size':14}\n",
    "matplotlib.rc('font', **font)\n",
    "matplotlib.rcParams['pdf.fonttype'] = 42\n",
    "\n",
    "CUSTOM_TITLE = None\n",
    "X_AXIS_LABEL = None\n",
    "Y_AXIS_LABEL = None\n",
    "X_AXIS_START_VAL = 0\n",
    "X_AXIS_INCREMENT = 1\n",
    "Y_AXIS_END_VAL = None\n",
    "\n",
    "def load_data(experiment_dir, experiment_agents):\n",
    "    '''\n",
    "    Args:\n",
    "        experiment_dir (str): Points to the file containing all the data.\n",
    "        experiment_agents (list): Points to which results files will be plotted.\n",
    "\n",
    "    Returns:\n",
    "        result (list): A 3d matrix containing rewards, where the dimensions are [algorithm][instance][episode].\n",
    "    '''\n",
    "\n",
    "    result = []\n",
    "    for alg in experiment_agents:\n",
    "\n",
    "        # Load the reward for all instances of each agent\n",
    "        all_reward = open(os.path.join(experiment_dir, str(alg)) + \".csv\", \"r\")\n",
    "        all_instances = []\n",
    "\n",
    "        # Put the reward instances into a list of floats.\n",
    "        for instance in all_reward.readlines():\n",
    "            all_episodes_for_instance = [float(r) for r in instance.split(\",\")[:-1] if len(r) > 0]\n",
    "            if len(all_episodes_for_instance) > 0:\n",
    "                all_instances.append(all_episodes_for_instance)\n",
    "\n",
    "        result.append(all_instances)\n",
    "\n",
    "    return result\n",
    "\n",
    "\n",
    "def average_data(data, cumulative=False):\n",
    "    '''\n",
    "    Args:\n",
    "        data (list): a 3D matrix, [algorithm][instance][episode]\n",
    "        cumulative (bool) *opt: determines if we should compute the average cumulative reward/cost or just regular.\n",
    "\n",
    "    Returns:\n",
    "        (list): a 2D matrix, [algorithm][episode], where the instance rewards have been averaged.\n",
    "    '''\n",
    "    num_algorithms = len(data)\n",
    "\n",
    "    result = [None for i in range(num_algorithms)] # [Alg][avgRewardEpisode], where avg is summed up to episode i if @cumulative=True\n",
    "\n",
    "    for i, all_instances in enumerate(data):\n",
    "\n",
    "        # Take the average.\n",
    "        num_instances = float(len(data[i]))\n",
    "        all_instances_sum = np.array(np.array(all_instances).sum(axis=0))\n",
    "        try:\n",
    "            avged = all_instances_sum / num_instances\n",
    "        except TypeError:\n",
    "            raise ValueError(\"(simple_rl) Plotting Error: an algorithm was run with inconsistent parameters (likely inconsistent number of Episodes/Instances. Try clearing old data).\")\n",
    "        \n",
    "        if cumulative:\n",
    "            # If we're summing over episodes.\n",
    "            temp = []\n",
    "            total_so_far = 0\n",
    "            for rew in avged:\n",
    "                total_so_far += rew\n",
    "                temp.append(total_so_far)\n",
    "\n",
    "            avged = temp\n",
    "\n",
    "        result[i] = avged\n",
    "\n",
    "    return result\n",
    "\n",
    "def compute_conf_intervals(data, cumulative=False):\n",
    "    '''\n",
    "    Args:\n",
    "        data (list): A 3D matrix, [algorithm][instance][episode]\n",
    "        cumulative (bool) *opt\n",
    "    '''\n",
    "\n",
    "    confidence_intervals_each_alg = [] # [alg][conf_inv_for_episode]\n",
    "\n",
    "    for i, all_instances in enumerate(data):\n",
    "\n",
    "        num_instances = len(data[i])\n",
    "        num_episodes = len(data[i][0])\n",
    "\n",
    "        all_instances_np_arr = np.array(all_instances)\n",
    "        alg_i_ci = []\n",
    "        total_so_far = np.zeros(num_instances)\n",
    "        for j in range(num_episodes):\n",
    "            # Compute datum for confidence interval.\n",
    "            episode_j_all_instances = all_instances_np_arr[:, j]\n",
    "\n",
    "            if cumulative:\n",
    "                # Cumulative.\n",
    "                summed_vector = np.add(episode_j_all_instances, total_so_far)\n",
    "                total_so_far = np.add(episode_j_all_instances, total_so_far)\n",
    "                episode_j_all_instances = summed_vector\n",
    "\n",
    "            # Compute the interval and add it to list.\n",
    "            conf_interv = compute_single_conf_interval(episode_j_all_instances)\n",
    "            alg_i_ci.append(conf_interv)\n",
    "\n",
    "        confidence_intervals_each_alg.append(alg_i_ci)\n",
    "\n",
    "    return confidence_intervals_each_alg\n",
    "\n",
    "\n",
    "def compute_single_conf_interval(datum):\n",
    "    '''\n",
    "    Args:\n",
    "        datum (list): A vector of data points to compute the confidence interval of.\n",
    "\n",
    "    Returns:\n",
    "        (float): Margin of error.\n",
    "    '''\n",
    "    std_deviation = np.std(datum)\n",
    "    std_error = 1.96*(std_deviation / math.sqrt(len(datum)))\n",
    "\n",
    "    return std_error\n",
    "\n",
    "\n",
    "def _format_title(plot_title):\n",
    "    plot_title = plot_title.replace(\"_\", \" \")\n",
    "    plot_title = plot_title.replace(\"-\", \" \")\n",
    "    if len(plot_title.split(\" \")) > 1:\n",
    "        plot_title_final = \" \".join([w[0].upper() + w[1:] for w in plot_title.strip().split(\" \")])\n",
    "\n",
    "    return plot_title_final\n",
    "\n",
    "def plot(results, experiment_dir, agents, plot_file_name=\"\", conf_intervals=[], use_cost=False, cumulative=False, episodic=True, open_plot=True, track_disc_reward=False):\n",
    "    '''\n",
    "    Args:\n",
    "        results (list of lists): each element is itself the reward from an episode for an algorithm.\n",
    "        experiment_dir (str): path to results.\n",
    "        agents (list): each element is an agent that was run in the experiment.\n",
    "        plot_file_name (str)\n",
    "        conf_intervals (list of floats) [optional]: confidence intervals to display with the chart.\n",
    "        use_cost (bool) [optional]: If true, plots are in terms of cost. Otherwise, plots are in terms of reward.\n",
    "        cumulative (bool) [optional]: If true, plots are cumulative cost/reward.\n",
    "        episodic (bool): If true, labels the x-axis \"Episode Number\". Otherwise, \"Step Number\". \n",
    "        open_plot (bool)\n",
    "        track_disc_reward (bool): If true, plots discounted reward.\n",
    "\n",
    "    Summary:\n",
    "        Makes (and opens) a single reward chart plotting all of the data in @data.\n",
    "    '''\n",
    "\n",
    "    # Set x-axis labels to be integers.\n",
    "    from matplotlib.ticker import MaxNLocator\n",
    "    ax = pyplot.figure().gca()\n",
    "    ax.xaxis.set_major_locator(MaxNLocator(integer=True))\n",
    "\n",
    "    # Some nice markers and colors for plotting.\n",
    "    markers = ['o', 's', 'D', '^', '*', 'x', 'p', '+', 'v','|']\n",
    "\n",
    "    x_axis_unit = \"episode\" if episodic else \"step\"\n",
    "\n",
    "    # Map them to floats in [0:1].\n",
    "    colors = [[shade / 255.0 for shade in rgb] for rgb in color_ls]\n",
    "\n",
    "    # Puts the legend into the best location in the plot and use a tight layout.\n",
    "    pyplot.rcParams['legend.loc'] = 'best'\n",
    "\n",
    "    # Negate everything if we're plotting cost.\n",
    "    if use_cost:\n",
    "        results = [[-x for x in alg] for alg in results]\n",
    "\n",
    "    agent_colors = _get_agent_colors(experiment_dir, agents)\n",
    "\n",
    "    # Make the plot.\n",
    "    print_prefix = \"\\nAvg. cumulative reward\" if cumulative else \"Avg. reward\"\n",
    "    # For each agent.\n",
    "    for i, agent_name in enumerate(agents):\n",
    "\n",
    "        # Add figure for this algorithm.\n",
    "        agent_color_index = i if agent_name not in agent_colors else agent_colors[agent_name]\n",
    "        agent_marker_index = agent_color_index\n",
    "        \n",
    "        # Grab new color/marker if we've gone over.\n",
    "        if agent_color_index >= len(colors):\n",
    "            agent_color_index = agent_color_index % len(colors)\n",
    "        if agent_marker_index >= len(markers):\n",
    "            agent_marker_index = agent_marker_index % len(markers)\n",
    "        \n",
    "        series_color = colors[agent_color_index]\n",
    "        series_marker = markers[agent_marker_index]\n",
    "        y_axis = results[i]\n",
    "        x_axis = list(drange(X_AXIS_START_VAL, X_AXIS_START_VAL + len(y_axis) * X_AXIS_INCREMENT, X_AXIS_INCREMENT))\n",
    "\n",
    "        # Plot Confidence Intervals.\n",
    "        if conf_intervals != []:\n",
    "            alg_conf_interv = conf_intervals[i]\n",
    "            top = np.add(y_axis, alg_conf_interv)\n",
    "            bot = np.subtract(y_axis, alg_conf_interv)\n",
    "            pyplot.fill_between(x_axis, top, bot, facecolor=series_color, edgecolor=series_color, alpha=0.25)\n",
    "        print(\"\\t\" + str(agents[i]) + \":\", round(y_axis[-1], 5) , \"(conf_interv:\", round(alg_conf_interv[-1], 2), \")\")\n",
    "\n",
    "        marker_every = max(len(y_axis) / 30,1)\n",
    "        pyplot.plot(x_axis, y_axis, color=series_color, marker=series_marker, markevery=marker_every, label=agent_name)\n",
    "        pyplot.legend()\n",
    "    print()\n",
    "    \n",
    "    # Configure plot naming information.\n",
    "    unit = \"Cost\" if use_cost else \"Reward\"\n",
    "    plot_label = \"Cumulative\" if cumulative else \"Average\"\n",
    "    if \"times\" in experiment_dir:\n",
    "        # If it's a time plot.\n",
    "        unit = \"Time\"\n",
    "\n",
    "    disc_ext = \"Discounted \" if track_disc_reward else \"\"\n",
    "\n",
    "    # Set names.\n",
    "    exp_dir_split_list = experiment_dir.split(\"/\")\n",
    "    if 'results' in exp_dir_split_list:\n",
    "        exp_name = exp_dir_split_list[exp_dir_split_list.index('results') + 1]\n",
    "    else:\n",
    "        exp_name = exp_dir_split_list[0]\n",
    "    experiment_dir = os.path.join(experiment_dir, \"\")\n",
    "    plot_file_name = os.path.join(experiment_dir, plot_file_name + \".pdf\") if plot_file_name != \"\" else experiment_dir + plot_label.lower() + \"_\" + unit.lower() + \".pdf\"\n",
    "    plot_title = CUSTOM_TITLE if CUSTOM_TITLE is not None else plot_label + \" \" + disc_ext + unit + \": \" + exp_name\n",
    "    if CUSTOM_TITLE is None:\n",
    "        plot_title = _format_title(plot_title)\n",
    "\n",
    "    # Axis labels.\n",
    "    x_axis_label = X_AXIS_LABEL if X_AXIS_LABEL is not None else x_axis_unit[0].upper() + x_axis_unit[1:] + \" Number\"\n",
    "    y_axis_label = Y_AXIS_LABEL if Y_AXIS_LABEL is not None else plot_label + \" \" + unit\n",
    "\n",
    "    # Pyplot calls.\n",
    "    pyplot.xlabel(x_axis_label)\n",
    "    pyplot.ylabel(y_axis_label)\n",
    "    pyplot.title(plot_title)\n",
    "    pyplot.grid(True)\n",
    "    pyplot.tight_layout() # Keeps the spacing nice.\n",
    "\n",
    "    # Save the plot.\n",
    "    pyplot.savefig(plot_file_name, format=\"pdf\")\n",
    "    \n",
    "    if open_plot:\n",
    "        # Open it.\n",
    "        open_prefix = \"gnome-\" if sys.platform == \"linux\" or sys.platform == \"linux2\" else \"\"\n",
    "        os.system(open_prefix + \"open \" + plot_file_name)\n",
    "\n",
    "    # Clear and close.\n",
    "    pyplot.cla()\n",
    "    pyplot.close()\n",
    "\n",
    "def make_plots(experiment_dir, experiment_agents, plot_file_name=\"\", cumulative=True, use_cost=False, episodic=True, open_plot=True, track_disc_reward=False, new_title=None, new_x_label=None, new_y_label=None):\n",
    "    '''\n",
    "    Args:\n",
    "        experiment_dir (str): path to results.\n",
    "        experiment_agents (list): agent names (looks for \"<agent-name>.csv\").\n",
    "        plot_file_name (str)\n",
    "        cumulative (bool): If true, plots show cumulative trr\n",
    "        use_cost (bool): If true, plots are in terms of cost. Otherwise, plots are in terms of reward.\n",
    "        episodic (bool): If true, labels the x-axis \"Episode Number\". Otherwise, \"Step Number\". \n",
    "        track_disc_reward (bool): If true, plots discounted reward (changes plot title, too).\n",
    "        new_title (str): Sets the title of the plot.\n",
    "        new_x_label (str): Sets the x axis label of the plot.\n",
    "        new_y_label (str): Sets the y axis label of the plot.\n",
    "    \n",
    "    Summary:\n",
    "        Creates plots for all agents run under the experiment.\n",
    "        Stores the plot in results/<experiment_name>/<plot_name>.pdf\n",
    "    '''\n",
    "\n",
    "    # Update plot labels if needed.\n",
    "    global CUSTOM_TITLE, X_AXIS_LABEL, Y_AXIS_LABEL\n",
    "    if new_title is not None:\n",
    "        CUSTOM_TITLE = new_title\n",
    "    if new_x_label is not None:\n",
    "        X_AXIS_LABEL = new_x_label\n",
    "    if new_y_label is not None:\n",
    "        Y_AXIS_LABEL = new_y_label\n",
    "\n",
    "    # Load the data.\n",
    "    data = load_data(experiment_dir, experiment_agents) # [alg][instance][episode]\n",
    "\n",
    "    # Average the data.\n",
    "    avg_data = average_data(data, cumulative=cumulative)\n",
    "\n",
    "    # Compute confidence intervals.\n",
    "    conf_intervals = compute_conf_intervals(data, cumulative=cumulative)\n",
    "\n",
    "    # Create plot.\n",
    "    plot(avg_data, experiment_dir, experiment_agents,\n",
    "                plot_file_name=plot_file_name,\n",
    "                conf_intervals=conf_intervals,\n",
    "                use_cost=use_cost,\n",
    "                cumulative=cumulative,\n",
    "                episodic=episodic,\n",
    "                open_plot=open_plot,\n",
    "                track_disc_reward=track_disc_reward)\n",
    "\n",
    "def drange(x_min, x_max, x_increment):\n",
    "    '''\n",
    "    Args:\n",
    "        x_min (float)\n",
    "        x_max (float)\n",
    "        x_increment (float)\n",
    "\n",
    "    Returns:\n",
    "        (generator): Makes a list.\n",
    "\n",
    "    Notes:\n",
    "        A range function for generating lists of floats. Based on code from stack overflow user Sam Bruns:\n",
    "            https://stackoverflow.com/questions/16105485/unsupported-operand-types-for-float-and-decimal\n",
    "    '''\n",
    "    x_min = decimal.Decimal(x_min)\n",
    "    while x_min < x_max:\n",
    "        yield float(x_min)\n",
    "        x_min += decimal.Decimal(str(x_increment))\n",
    "\n",
    "def _get_agent_names(data_dir):\n",
    "    '''\n",
    "    Args:\n",
    "        data_dir (str)\n",
    "\n",
    "    Returns:\n",
    "        (list)\n",
    "    '''\n",
    "    from simple_rl.experiments import Experiment\n",
    "\n",
    "    try:\n",
    "        params_file = open(os.path.join(data_dir, Experiment.EXP_PARAM_FILE_NAME), \"r\")\n",
    "    except IOError:\n",
    "        # No param file.\n",
    "        return [agent_file.replace(\".csv\", \"\") for agent_file in os.listdir(data_dir) if os.path.isfile(os.path.join(data_dir, agent_file)) and \".csv\" in agent_file]\n",
    "\n",
    "    agent_names = []\n",
    "    agent_flag = False\n",
    "\n",
    "    for line in params_file.readlines():\n",
    "        if \"Agents\" in line:\n",
    "            agent_flag = True\n",
    "            continue\n",
    "        if \"Params\" in line:\n",
    "            agent_flag = False\n",
    "        if agent_flag:\n",
    "            agent_names.append(line.split(\",\")[0].strip())\n",
    "\n",
    "    return agent_names\n",
    "\n",
    "def _get_agent_colors(data_dir, agents):\n",
    "    '''\n",
    "    Args:\n",
    "        data_dir (str)\n",
    "        agents (list)\n",
    "\n",
    "    Returns:\n",
    "        (list)\n",
    "    '''\n",
    "    from simple_rl.experiments import Experiment\n",
    "\n",
    "    try:\n",
    "        params_file = open(os.path.join(data_dir, Experiment.EXP_PARAM_FILE_NAME), \"r\")\n",
    "    except IOError:\n",
    "        # No param file.\n",
    "        return {agent : i for i, agent in enumerate(agents)}\n",
    "\n",
    "    colors = {}\n",
    "\n",
    "    # Check if episodes > 1.\n",
    "    for line in params_file.readlines():\n",
    "        for agent_name in agents:\n",
    "            if agent_name == line.strip().split(\",\")[0]:\n",
    "                colors[agent_name] = int(line[-2])\n",
    "\n",
    "    return colors\n",
    "\n",
    "def _is_episodic(data_dir):\n",
    "    '''\n",
    "    Returns:\n",
    "        (bool) True iff the experiment was episodic.\n",
    "    '''\n",
    "    from simple_rl.experiments import Experiment\n",
    "\n",
    "    # Open param file for the experiment.\n",
    "    if not os.path.exists(os.path.join(data_dir, Experiment.EXP_PARAM_FILE_NAME)):\n",
    "        print(\"Warning: no experiment parameters file found for experiment. Assuming non-episodic.\")\n",
    "        return False\n",
    "\n",
    "    params_file = open(os.path.join(data_dir, Experiment.EXP_PARAM_FILE_NAME), \"r\")\n",
    "\n",
    "    # Check if episodes > 1.\n",
    "    for line in params_file.readlines():\n",
    "        if \"episodes\" in line:\n",
    "            vals = line.strip().split(\":\")\n",
    "            return int(vals[1]) > 1\n",
    "\n",
    "def _is_disc_reward(data_dir):\n",
    "    '''\n",
    "    Returns:\n",
    "        (bool) True iff the experiment recorded discounted reward.\n",
    "    '''\n",
    "    from simple_rl.experiments import Experiment\n",
    "\n",
    "    # Open param file for the experiment.\n",
    "    if not os.path.exists(os.path.join(data_dir, Experiment.EXP_PARAM_FILE_NAME)):\n",
    "        print(\"Warning: no experiment parameters file found for experiment. Assuming non-episodic.\")\n",
    "        return False\n",
    "\n",
    "    params_file = open(os.path.join(data_dir, Experiment.EXP_PARAM_FILE_NAME), \"r\")\n",
    "\n",
    "    # Check if episodes > 1.\n",
    "    for line in params_file.readlines():\n",
    "        if \"track_disc_reward\" in line:\n",
    "            vals = line.strip().split(\":\")\n",
    "            if \"True\" == vals[1].strip():\n",
    "                return True\n",
    "\n",
    "    return False\n",
    "\n",
    "def parse_args():\n",
    "    '''\n",
    "    Summary:\n",
    "        Parses two arguments, 'dir' (directory pointer) and 'a' (bool to indicate avg. plot).\n",
    "    '''\n",
    "    parser = argparse.ArgumentParser()\n",
    "    parser.add_argument(\"-dir\", type = str, help = \"Path to relevant csv files of data.\")\n",
    "    parser.add_argument(\"-a\", type = bool, default=False, help = \"If true, plots average reward (default is cumulative).\")\n",
    "    return parser.parse_args()\n",
    "\n",
    "\n",
    "def main():\n",
    "    '''\n",
    "    Summary:\n",
    "        For manual plotting.\n",
    "    '''\n",
    "    \n",
    "    # Parse args.\n",
    "    args = parse_args()\n",
    "\n",
    "    # Grab agents.\n",
    "    data_dir = args.dir\n",
    "    agent_names = _get_agent_names(data_dir)\n",
    "    if len(agent_names) == 0:\n",
    "        raise ValueError(\"Error: no csv files found.\")\n",
    "\n",
    "    if data_dir[-1] != \"/\":\n",
    "        data_dir = data_dir + \"/\"\n",
    "\n",
    "    cumulative = not(args.a)\n",
    "    episodic = _is_episodic(data_dir)\n",
    "    track_disc_reward = _is_disc_reward(data_dir)\n",
    "    plot_file_name = \"\"\n",
    "\n",
    "    # Success plot.\n",
    "    if \"success\" in data_dir:\n",
    "        global X_AXIS_LABEL, Y_AXIS_LABEL, CUSTOM_TITLE\n",
    "        plot_file_name = \"Success_Rate\"\n",
    "        CUSTOM_TITLE = \"Success Rate\"\n",
    "        X_AXIS_LABEL = \"Episode\"\n",
    "        Y_AXIS_LABEL = \"Avg. % Success\"\n",
    "        cumulative = False\n",
    "\n",
    "    # Plot.\n",
    "    make_plots(data_dir, agent_names, cumulative=cumulative, episodic=episodic, plot_file_name=plot_file_name, track_disc_reward=track_disc_reward)\n",
    " \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/anaconda3/lib/python3.6/site-packages/simple_rl/tasks/gather/GatherStateClass.py:8: UserWarning: matplotlib.pyplot as already been imported, this call will have no effect.\n",
      "  matplotlib.use('TkAgg')\n",
      "/anaconda3/lib/python3.6/site-packages/simple_rl/utils/chart_utils.py:29: UserWarning: matplotlib.pyplot as already been imported, this call will have no effect.\n",
      "  matplotlib.use('TkAgg')\n"
     ]
    },
    {
     "ename": "KeyError",
     "evalue": "0",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "\u001b[0;32m/anaconda3/lib/python3.6/site-packages/pandas/core/indexes/base.py\u001b[0m in \u001b[0;36mget_loc\u001b[0;34m(self, key, method, tolerance)\u001b[0m\n\u001b[1;32m   3077\u001b[0m             \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 3078\u001b[0;31m                 \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_engine\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_loc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   3079\u001b[0m             \u001b[0;32mexcept\u001b[0m \u001b[0mKeyError\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32mpandas/_libs/index.pyx\u001b[0m in \u001b[0;36mpandas._libs.index.IndexEngine.get_loc\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32mpandas/_libs/index.pyx\u001b[0m in \u001b[0;36mpandas._libs.index.IndexEngine.get_loc\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32mpandas/_libs/hashtable_class_helper.pxi\u001b[0m in \u001b[0;36mpandas._libs.hashtable.PyObjectHashTable.get_item\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32mpandas/_libs/hashtable_class_helper.pxi\u001b[0m in \u001b[0;36mpandas._libs.hashtable.PyObjectHashTable.get_item\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;31mKeyError\u001b[0m: 0",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-38-97bdb404bc92>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mplot\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mexperiment_dir\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'/'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0magents\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'DQN'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m<ipython-input-36-ef9cfed9e2d8>\u001b[0m in \u001b[0;36mplot\u001b[0;34m(results, experiment_dir, agents, plot_file_name, conf_intervals, use_cost, cumulative, episodic, open_plot, track_disc_reward)\u001b[0m\n\u001b[1;32m    230\u001b[0m         \u001b[0mseries_color\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcolors\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0magent_color_index\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    231\u001b[0m         \u001b[0mseries_marker\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmarkers\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0magent_marker_index\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 232\u001b[0;31m         \u001b[0my_axis\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mresults\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    233\u001b[0m         \u001b[0mx_axis\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_AXIS_START_VAL\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mX_AXIS_START_VAL\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my_axis\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0mX_AXIS_INCREMENT\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mX_AXIS_INCREMENT\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    234\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/anaconda3/lib/python3.6/site-packages/pandas/core/frame.py\u001b[0m in \u001b[0;36m__getitem__\u001b[0;34m(self, key)\u001b[0m\n\u001b[1;32m   2686\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_getitem_multilevel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2687\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2688\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_getitem_column\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2689\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2690\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_getitem_column\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/anaconda3/lib/python3.6/site-packages/pandas/core/frame.py\u001b[0m in \u001b[0;36m_getitem_column\u001b[0;34m(self, key)\u001b[0m\n\u001b[1;32m   2693\u001b[0m         \u001b[0;31m# get column\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2694\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcolumns\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mis_unique\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2695\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_get_item_cache\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2696\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2697\u001b[0m         \u001b[0;31m# duplicate columns & possible reduce dimensionality\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/anaconda3/lib/python3.6/site-packages/pandas/core/generic.py\u001b[0m in \u001b[0;36m_get_item_cache\u001b[0;34m(self, item)\u001b[0m\n\u001b[1;32m   2487\u001b[0m         \u001b[0mres\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcache\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mitem\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2488\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mres\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2489\u001b[0;31m             \u001b[0mvalues\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_data\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mitem\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2490\u001b[0m             \u001b[0mres\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_box_item_values\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mitem\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalues\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2491\u001b[0m             \u001b[0mcache\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mitem\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mres\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/anaconda3/lib/python3.6/site-packages/pandas/core/internals.py\u001b[0m in \u001b[0;36mget\u001b[0;34m(self, item, fastpath)\u001b[0m\n\u001b[1;32m   4113\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   4114\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0misna\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mitem\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 4115\u001b[0;31m                 \u001b[0mloc\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitems\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_loc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mitem\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   4116\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   4117\u001b[0m                 \u001b[0mindexer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0marange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitems\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0misna\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitems\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/anaconda3/lib/python3.6/site-packages/pandas/core/indexes/base.py\u001b[0m in \u001b[0;36mget_loc\u001b[0;34m(self, key, method, tolerance)\u001b[0m\n\u001b[1;32m   3078\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_engine\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_loc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3079\u001b[0m             \u001b[0;32mexcept\u001b[0m \u001b[0mKeyError\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 3080\u001b[0;31m                 \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_engine\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_loc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_maybe_cast_indexer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   3081\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3082\u001b[0m         \u001b[0mindexer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_indexer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmethod\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmethod\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtolerance\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtolerance\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32mpandas/_libs/index.pyx\u001b[0m in \u001b[0;36mpandas._libs.index.IndexEngine.get_loc\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32mpandas/_libs/index.pyx\u001b[0m in \u001b[0;36mpandas._libs.index.IndexEngine.get_loc\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32mpandas/_libs/hashtable_class_helper.pxi\u001b[0m in \u001b[0;36mpandas._libs.hashtable.PyObjectHashTable.get_item\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32mpandas/_libs/hashtable_class_helper.pxi\u001b[0m in \u001b[0;36mpandas._libs.hashtable.PyObjectHashTable.get_item\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;31mKeyError\u001b[0m: 0"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plot(data, experiment_dir='/', agents='DQN')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_json('mydqn_micro_with_swarmed_log.json')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<bound method NDFrame.head of             loss  mean_absolute_error       mean_q  episode_reward  \\\n",
       "0       0.000000             0.000000     0.000000             1.0   \n",
       "1       0.000000             0.000000     0.000000             1.0   \n",
       "2       0.000000             0.000000     0.000000             1.0   \n",
       "3       0.000000             0.000000     0.000000             1.0   \n",
       "4  146298.139162           240.871178   606.281828           215.5   \n",
       "5   79271.046875           352.651154  1131.826172           615.0   \n",
       "6   21459.482422           565.175903  1657.313721             4.5   \n",
       "\n",
       "   nb_episode_steps  nb_steps  episode     duration  \n",
       "0                 1         1        0    81.938477  \n",
       "1                 1         2        1    92.686213  \n",
       "2                 1         3        2    97.995761  \n",
       "3                 1         4        3    98.231826  \n",
       "4               431       435        4   324.018177  \n",
       "5              1230      1665        5  2178.933476  \n",
       "6                 9      1674        6    16.174072  >"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.head"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[<matplotlib.axes._subplots.AxesSubplot object at 0x11905f2e8>,\n",
       "        <matplotlib.axes._subplots.AxesSubplot object at 0x11dbe3550>,\n",
       "        <matplotlib.axes._subplots.AxesSubplot object at 0x11dc0e9b0>],\n",
       "       [<matplotlib.axes._subplots.AxesSubplot object at 0x11dc38f28>,\n",
       "        <matplotlib.axes._subplots.AxesSubplot object at 0x11dc694e0>,\n",
       "        <matplotlib.axes._subplots.AxesSubplot object at 0x11dc8fa58>],\n",
       "       [<matplotlib.axes._subplots.AxesSubplot object at 0x11dcb7fd0>,\n",
       "        <matplotlib.axes._subplots.AxesSubplot object at 0x11dce65c0>,\n",
       "        <matplotlib.axes._subplots.AxesSubplot object at 0x11dce65f8>]],\n",
       "      dtype=object)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.hist(bins=50, figsize=(20,25))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/anaconda3/lib/python3.6/site-packages/ipykernel_launcher.py:3: UserWarning: matplotlib.pyplot as already been imported, this call will have no effect.\n",
      "  This is separate from the ipykernel package so we can avoid doing imports until\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([<matplotlib.axes._subplots.AxesSubplot object at 0x1a2f6a5a58>],\n",
       "      dtype=object)"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib\n",
    "\n",
    "matplotlib.use('TkAgg')\n",
    "color_ls = [[118, 167, 125], [102, 120, 173],\\\n",
    "            [198, 113, 113], [94, 94, 94],\\\n",
    "            [169, 193, 213], [230, 169, 132],\\\n",
    "            [192, 197, 182], [210, 180, 226]]\n",
    "\n",
    "# Set font.\n",
    "font = {'size':14}\n",
    "matplotlib.rc('font', **font)\n",
    "matplotlib.rcParams['pdf.fonttype'] = 42\n",
    "data['mean_q'].plot(kind='density', grid=True, sharex=True, legend=True, xerr=data['mean_absolute_error'], subplots=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.plot(kind=\"scatter\", x=\"episode\", y=\"duration\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.utils import plot_model\n",
    "plot_model(model, show_shapes=True, expand_nested=True, rankdir='TB', to_file='model.png')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from IPython.display import SVG\n",
    "from keras.utils.vis_utils import model_to_dot\n",
    "\n",
    "SVG(model_to_dot(model).create(prog='dot', format='svg'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
