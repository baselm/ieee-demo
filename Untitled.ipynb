{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "import gym\n",
    "from gym import error, spaces, utils\n",
    "from gym.utils import seeding\n",
    "\n",
    "class FooEnv(gym.Env):\n",
    "  metadata = {'render.modes': ['human']}\n",
    "  def get_cpu_observation():\n",
    "        response = requests.get('http://192.168.99.100:8888/cpu', timeout=5)\n",
    "        results = response.json()\n",
    "        if len(results) > 0:\n",
    "                cpu = results['cpu']\n",
    "                prediction = results['prediction']\n",
    "                anomalyScore = results['anomalyScore']\n",
    "                anomalyLikelihood = results['anomalyLikelihood']\n",
    "                utility_cpu = results['utility_cpu']\n",
    "                cpu_axis=[cpu, prediction, anomalyScore, anomalyLikelihood, utility_cpu]\n",
    "        return np.array(cpu_axis) \n",
    "\n",
    "  def get_mem_observation():\n",
    "    response = requests.get('http://192.168.99.100:8888/mem', timeout=5)\n",
    "    results = response.json()\n",
    "    if len(results) > 0:\n",
    "        mem = results['mem']\n",
    "        prediction = results['prediction']\n",
    "        anomalyScore = results['anomalyScore']\n",
    "        anomalyLikelihood = results['anomalyLikelihood']\n",
    "        utility_mem = results['utility_mem']\n",
    "        #mem_axis=[mem, prediction, anomalyScore, anomalyLikelihood, utility_mem]    \n",
    "    mem_axis=[mem, prediction, anomalyScore, anomalyLikelihood, utility_mem]\n",
    "    return np.array(mem_axis) \n",
    "  def get_net_observation():\n",
    "    response = requests.get('http://192.168.99.100:8888/net', timeout=5)\n",
    "    results = response.json()\n",
    "    if len(results) > 0:\n",
    "        net = results['net']\n",
    "        prediction = results['prediction']\n",
    "        anomalyScore = results['anomalyScore']\n",
    "        anomalyLikelihood = results['anomalyLikelihood']\n",
    "        utility_net = results['utility_net']\n",
    "         \n",
    "    net_axis=[net, prediction, anomalyScore, anomalyLikelihood, utility_net]\n",
    "    return np.array(net_axis) \n",
    "\n",
    "  def get_disk_observation():\n",
    "    response = requests.get('http://192.168.99.100:8888/disk', timeout=5)\n",
    "    if response is not None:\n",
    "        results = response.json()\n",
    "        if len(results) > 0:\n",
    "            disk = results['disk']\n",
    "            prediction = results['prediction']\n",
    "            anomalyScore = results['anomalyScore']\n",
    "            anomalyLikelihood = results['anomalyLikelihood']\n",
    "            utility_mem = results['utility_disk']\n",
    "            disk_axis=[disk, prediction, anomalyScore, anomalyLikelihood, utility_mem]\n",
    "    return np.array(disk_axis) \n",
    "\n",
    "  def __init__(self):\n",
    "    \"\"\"\n",
    "    Description:\n",
    "        A pole is attached by an un-actuated joint to a cart, which moves along a frictionless track. The pendulum starts upright, and the goal is to prevent it from falling over by increasing and reducing the cart's velocity.\n",
    "    Source:\n",
    "        This environment corresponds to the version of the cart-pole problem described by Barto, Sutton, and Anderson\n",
    "    Observation: \n",
    "        Type: Box(4)\n",
    "        Num\tObservation                 Min         Max\n",
    "        0\tCPU Utility                -4.8            4.8\n",
    "        1\tmemory Utility             -4.8            4.8\n",
    "        2\tDisk Utility               -4.8            4.8\n",
    "        3\tNet Utility      \t\t   -4.8            4.8\n",
    "        \n",
    "    Actions:\n",
    "        Type: Discrete(2)\n",
    "        Num\tAction\n",
    "        0\tStay in State S0\n",
    "        1\tScale A Service Down Move to State S0\n",
    "        2 \tScale Service  Up\n",
    "        3  \tRemove Node\n",
    "        4\tAdd Node \n",
    "        5 \tInitialise new swarm with state\n",
    "        \n",
    "     Reward:\n",
    "        Reward SoftMAX(Ucpu, Umem, Unet, Udisk)\n",
    "    Starting State:\n",
    "        All observations are assigned to current observation of S0\n",
    "    Episode Termination:\n",
    "        Adaptation Time is >= 300MS \n",
    "        Number of Nodes <=1 \n",
    "        Number of Nodes >= Maximum Number of Node \n",
    "        Number of Replicas <= min(Service)\n",
    "        Number of Replicas >= Max(service)\n",
    "        Considered solved when services are fully converged\n",
    "    \"\"\"\n",
    "    self.cpu_axis  = self.get_cpu_observation()\n",
    "    self.mem_axis = self.get_mem_observation()\n",
    "    self.disk_axis = self.get_disk_observation()\n",
    "    self.net_axis  = self.get_net_observation()\n",
    "\n",
    "    self.action_space = spaces.Discrete(5)\n",
    "    high = np.array([\n",
    "            self.cpu_axis,\n",
    "            self.mem_axis,\n",
    "            self.disk_axis,\n",
    "            self.net_axis])\n",
    "    self.observation_space = spaces.Box(-high, high, dtype=np.float32)\n",
    "    self.seed()\n",
    "    self.viewer = None\n",
    "    self.state = None\n",
    "    self.steps_beyond_done = None\n",
    "    \n",
    "def seed(self, seed=None):\n",
    "        self.np_random, seed = seeding.np_random(seed)\n",
    "        return [seed]\n",
    "\n",
    "def step(self, action):\n",
    "    assert self.action_space.contains(action), \"%r (%s) invalid\"%(action, type(action))\n",
    "    state = self.state\n",
    "    cpu_axis, mem_axis, disk_axis, net_axis = state\n",
    "    if action == -1:\n",
    "        print(\"Scale Down Move to State S1\")\n",
    "        #Reward = max of utility fitness \n",
    "        current_state = get_current_stat()\n",
    "        reward= current_state - past_stat\n",
    "        done= False \n",
    "        info = \"Scale Down Move to State S1\"\n",
    "    elif action == 0: \n",
    "        print(\"Stay in State S0\")\n",
    "        current_state = get_current_stat()\n",
    "        reward= current_state - past_stat\n",
    "\n",
    "        done= True \n",
    "        info = \"Stay in State S0\"\n",
    "    elif action == 1: \n",
    "        print(\"Scale Service UP S2\")\n",
    "        current_state = get_current_stat()\n",
    "        reward= current_state - past_stat\n",
    "        done= False \n",
    "        info = \"Stay in State S0\"\n",
    "    elif action == 2: \n",
    "        print(\"Remove Node S3\")\n",
    "        current_state = get_current_stat()\n",
    "        reward= current_state - past_stat\n",
    "        done= False\n",
    "        info = \"Remove Node S3\"\n",
    "    elif action == 3: \n",
    "        print(\"Mantain Cluster State S0\")\n",
    "        current_state = get_current_stat()\n",
    "        reward= current_state - past_stat\n",
    "        done= False\n",
    "        info = \"Mantain Cluster State S0\"\n",
    "    elif action == 4: \n",
    "        print(\"Add Node S4\")\n",
    "        current_state = get_current_stat()\n",
    "        reward= current_state - past_stat\n",
    "        done= False\n",
    "        info = \"Add Node S4\"\n",
    "    else: \n",
    "        print (\"action not defined\")\n",
    "        current_state = get_current_stat()\n",
    "        reward= -1\n",
    "        info = \"action not defined\"\n",
    "    if done: \n",
    "        reward = 1.0\n",
    "    elif self.steps_beyond_done is None:\n",
    "        #Adaptation Failed \n",
    "        reward = 1.0 \n",
    "        self.steps_beyond_done = 0\n",
    "    else: \n",
    "        if self.steps_beyond_done == 0:\n",
    "            logger.warn(\"You are calling 'step()' even though this environment has already returned done = True. You should always call 'reset()' once you receive 'done = True' -- any further steps are undefined behavior.\")\n",
    "            self.steps_beyond_done += 1\n",
    "            reward = 0.0\n",
    "    state = get_observation()\n",
    "    return np.array(self.state), reward, done, {}\n",
    "\n",
    "\n",
    "\n",
    "def reset(self):\n",
    "    self.state = self.np_random.uniform(low=-0.05, high=0.05, size=(4,))\n",
    "    self.steps_beyond_done = None\n",
    "    return np.array(self.state)\n",
    "\n",
    "def render(self, mode='human', close=False):\n",
    "  \tlogger.warn(\"View is not allowed in this environment\")\n",
    "  \treturn 0 \n",
    "\n",
    "def close(self):\n",
    "    if self.viewer:\n",
    "        self.viewer.close()\n",
    "        self.viewer = None\n",
    "\n",
    "  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
